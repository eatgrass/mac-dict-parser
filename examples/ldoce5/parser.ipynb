{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../lib')\n",
    "\n",
    "from readmdict import MDX\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "mdx = MDX('./LDOCE5++ V 1-35.mdx') # change to your own path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parser for LDOCE5\n",
    "entries = {}\n",
    "def extract(dom):\n",
    "    try:\n",
    "        el_body = dom.find(\"span\", {\"class\": \"lm5ppbody\"})\n",
    "        if el_body is None:\n",
    "            return None\n",
    "        el_dict = el_body.find(\"div\", {\"class\": \"dictionary\"})\n",
    "        if el_dict is not None:\n",
    "            el_family = el_dict.find(\"div\", {\"class\": \"wordfams\"})\n",
    "            title = el_body.find(\"h1\", {\"class\": \"pagetitle\"}).text\n",
    "            family = {}\n",
    "            entry_el = el_body.find_all(\"span\", {\"class\": \"dictentry\"})\n",
    "            definitions = []\n",
    "\n",
    "            if el_family is not None:\n",
    "                extract_family(el_family)\n",
    "            \n",
    "            if entry_el is not None:\n",
    "                for d in entry_el:\n",
    "                    definitions.append(extract_def(d))\n",
    "\n",
    "            return {\n",
    "                'title': title,\n",
    "                'definitions': definitions,\n",
    "                'link': None,\n",
    "            }\n",
    "\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as err:\n",
    "        print(dom)\n",
    "        raise err\n",
    "\n",
    "def extract_family(el_family):\n",
    "    pass\n",
    "\n",
    "def extract_def(d):\n",
    "    definition = {}\n",
    "    definition['business'] = 'bussdict' in d['class']\n",
    "    definition['pron'] =  d.find(\"span\", {\"class\": \"PRON\"}).get_text(strip=True) if d.find(\"span\", {\"class\": \"PRON\"}) is not None else None\n",
    "    definition['a_pron'] =  d.find(\"span\", {\"class\": \"AMEVARPRON\"}).get_text(strip=True).replace(\"$\",\"\").strip() if d.find(\"span\", {\"class\": \"AMEVARPRON\"}) is not None else None\n",
    "    definition['gram'] = d.find(\"span\", {\"class\": \"GRAM\"}).get_text(strip=True) if d.find(\"span\", {\"class\": \"GRAM\"}) is not None else None\n",
    "\n",
    "    definition['level'] = d.find(\"span\", {\"class\": \"tooltip LEVEL\"}).get_text(strip=True) if d.find(\"span\", {\"class\": \"tooltip LEVEL\"}) is not None else None\n",
    "    el_pos = d.find('span', {'class': 'lm5pp_POS'})\n",
    "    definition['pos'] = el_pos.get_text(strip=True) if el_pos is not None else None\n",
    "    definition['freq'] = [f.get_text(strip=True) for f in d.find_all(\"span\", {\"class\": \"FREQ\"})]\n",
    "    definition['inflections'] = [ i.get_text() for i in d.find_all(\"span\",{\"class\": \"PTandPP\"})]\n",
    "    definition['sense'] = []\n",
    "\n",
    "    example_filter = set()\n",
    "\n",
    "    for el_sense in d.find_all(\"span\", {\"class\": \"Sense\"}):\n",
    "        sense = {}\n",
    "        sense['examples'] = []\n",
    "        sense['gram_examples'] = []\n",
    "        el_sign = el_sense.find(\"span\", {\"class\": \"SIGNPOST\"})\n",
    "        if el_sign is not None:\n",
    "            sense['cn_sign'] = el_sign.find(\"span\", {\"class\": \"cn_txt\"}).extract().get_text(strip=True) if el_sign.find(\"span\", {\"class\": \"cn_txt\"}) is not None else None\n",
    "            sense['en_sign'] = el_sign.get_text(strip=True)\n",
    "        else:\n",
    "            sense['cn_sign'] = None\n",
    "            sense['en_sign'] = None\n",
    "\n",
    "        el_gram = el_sense.find(\"span\", {\"class\": \"GRAM\"})\n",
    "        if el_gram is not None:\n",
    "            sense['gram'] = el_gram.get_text(strip=True)\n",
    "        else:\n",
    "            sense['gram'] = None\n",
    "\n",
    "        el_defs = el_sense.find_all(\"span\", {\"class\": \"DEF\"})\n",
    "        if el_defs:\n",
    "            sense['en_def'] = el_defs.pop(0).get_text().strip()\n",
    "            sense['cn_def'] = el_defs.pop(0).get_text().strip() if el_defs else None\n",
    "        else:\n",
    "            sense['en_def'] = None\n",
    "            sense['cn_def'] = None\n",
    "\n",
    "        el_examples = el_sense.find_all(\"span\", {\"class\": \"EXAMPLE\"})\n",
    "        if el_examples:\n",
    "            for el_exm in el_examples:\n",
    "                example = {}\n",
    "                el_cn_exam = el_exm.find(\"span\", {\"class\": \"cn_txt\"})\n",
    "                example['cn_exm'] = el_cn_exam.extract().get_text().strip() if el_cn_exam is not None else None\n",
    "                example['en_exm'] = el_exm.get_text().strip()\n",
    "                if example['en_exm'] not in example_filter:\n",
    "                    sense['examples'].append(example)\n",
    "                    example_filter.add(example['en_exm'])\n",
    "\n",
    "        el_gram_examples = el_sense.find_all(\"span\", {\"class\": \"GramExa\"})\n",
    "\n",
    "        if el_gram_examples:\n",
    "            for el_gram_exm in el_gram_examples:\n",
    "                gram_examples ={}\n",
    "                el_form = el_gram_exm.find(\"span\", {\"class\": \"PROPFORM\"})\n",
    "                gram_examples['form'] = el_form.get_text().strip() if el_form is not None else None\n",
    "                el_cn_gram_exm = el_gram_exm.find(\"span\", {\"class\": \"cn_txt\"})\n",
    "                gram_examples['cn_gram_exm'] = el_cn_gram_exm.extract().get_text().strip() if el_cn_gram_exm is not None else None\n",
    "                gram_examples['en_gram_exm'] = el_gram_exm.get_text().strip()\n",
    "                sense['gram_examples'].append(gram_examples)\n",
    "\n",
    "        definition['sense'].append(sense)\n",
    "    \n",
    "    return definition\n",
    "        # el_boxes = el_sense.find(\"span\",{\"class\": \"BoxHide\"})\n",
    "\n",
    "        # if el_boxes is not None:\n",
    "        #     if el_boxes.find(\"span\",{\"class\": \"foldsign\"}) is not None:\n",
    "        #         el_boxes.find(\"span\",{\"class\": \"foldsign\"}).extract()\n",
    "            \n",
    "        #     box_title = el_boxes.find(\"span\", {\"class\": \"lm5ppBoxHead\"}).get_text().strip() if el_boxes.find(\"span\", {\"class\": \"lm5ppBoxHead\"}) is not None else None\n",
    "\n",
    "        #     print(box_title)\n",
    "        #     for el_expl_example in el_boxes.find_all(next_expl_or_example):\n",
    "        #         # el_expl_example.extract()\n",
    "        #         el_cn_expl = el_expl_example.find(\"span\",{\"class\": \"cn_txt\"})\n",
    "        #         cn_expl = el_cn_expl.extract().get_text().strip() if el_cn_expl is not None else None\n",
    "        #         en_expl = el_expl_example.get_text().strip()\n",
    "        #         warning = el_expl_example.find(\"span\",{\"class\": \"warning\"}) is not None or el_expl_example.find(\"span\",{\"class\": \"dont_say\"}) is not None\n",
    "        #         if cn_expl is not None:\n",
    "        #             print(\"{},{},{}\".format(warning,en_expl,cn_expl))\n",
    "        #             pass\n",
    "                \n",
    "                # while el_expl.next_element is not None and el_expl.next_element.has_attr(\"class\"):\n",
    "                #     print(\"{},{},{}\".format(warning,en_expl,cn_expl))\n",
    "                #     print(el_expl.next_element[\"class\"])\n",
    "                #     el_gram_example = el_expl.next_element.extract()\n",
    "                    # el_cn_gram_example = el_gram_example.find(\"span\",{\"class\": \"cn_txt\"})\n",
    "                    # cn_gram_example = el_cn_gram_example.extract().get_text().strip() if el_cn_gram_example is not None else None\n",
    "                    # en_gram_example = el_gram_example.get_text().strip()\n",
    "                    # print(\"{},{},{}\".format(en_gram_example,cn_gram_example))\n",
    "\n",
    "\n",
    "\n",
    "def next_expl_or_example(el):\n",
    "    return el.has_attr(\"class\") and (\"EXAMPLE\" in el[\"class\"] or \"EXPL\" in el[\"class\"])\n",
    "\n",
    "r = re.compile(r'@@@LINK=(.*)')\n",
    "\n",
    "def parse(index ,content):\n",
    "    if \"@@@LINK\" in content:\n",
    "        if 'ldoce' not in content:\n",
    "            matches = r.search(content)\n",
    "            return {\n",
    "                'index': index,\n",
    "                'definitions': None,\n",
    "                'link': matches.group(1).strip()\n",
    "            }\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        dom = BeautifulSoup(content, \"html.parser\")\n",
    "        return extract(dom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignore duplicated index: act up\n",
      "ignore duplicated index: add something ↔ on\n",
      "ignore duplicated index: ageing\n",
      "ignore duplicated index: all comers\n",
      "ignore duplicated index: all round\n",
      "ignore duplicated index: ANC, the\n",
      "ignore duplicated index: back to back\n",
      "ignore duplicated index: bad hair day\n",
      "ignore duplicated index: bail out\n",
      "ignore duplicated index: balls something ↔ up\n",
      "ignore duplicated index: bang somebody/something ↔ up\n",
      "ignore duplicated index: bases\n",
      "ignore duplicated index: bass\n",
      "ignore duplicated index: bathing\n",
      "ignore duplicated index: beat up\n",
      "ignore duplicated index: be hoist with/by your own petard\n",
      "ignore duplicated index: best\n",
      "ignore duplicated index: better\n",
      "ignore duplicated index: big shot\n",
      "ignore duplicated index: blast off\n",
      "ignore duplicated index: blow up\n",
      "ignore duplicated index: brave new world\n",
      "ignore duplicated index: break in\n",
      "ignore duplicated index: British National Party, the\n",
      "ignore duplicated index: British Rail\n",
      "ignore duplicated index: British Telecom\n",
      "ignore duplicated index: brush somebody/something ↔ off\n",
      "ignore duplicated index: build up\n",
      "ignore duplicated index: bust up\n",
      "ignore duplicated index: call in\n",
      "ignore duplicated index: call out\n",
      "ignore duplicated index: call up\n",
      "ignore duplicated index: calves\n",
      "ignore duplicated index: carry on\n",
      "ignore duplicated index: carry something ↔ over\n",
      "ignore duplicated index: carve somebody/something ↔ up\n",
      "ignore duplicated index: cast off\n",
      "ignore duplicated index: cave in\n",
      "ignore duplicated index: check in\n",
      "ignore duplicated index: clean up\n",
      "ignore duplicated index: clear out\n",
      "ignore duplicated index: climb down\n",
      "ignore duplicated index: close up\n",
      "ignore duplicated index: cock something ↔ up\n",
      "ignore duplicated index: coconut shy\n",
      "ignore duplicated index: coloured\n",
      "ignore duplicated index: come on\n",
      "ignore duplicated index: Communist Party\n",
      "ignore duplicated index: cop out\n",
      "ignore duplicated index: cover up\n",
      "ignore duplicated index: crack up\n",
      "ignore duplicated index: cut up\n",
      "ignore duplicated index: Daughters of the American Revolution, the\n",
      "ignore duplicated index: Department for Culture, Media and Sport, the\n",
      "ignore duplicated index: Deutschmark\n",
      "ignore duplicated index: does\n",
      "ignore duplicated index: do or die\n",
      "ignore duplicated index: drier\n",
      "ignore duplicated index: drive somebody/something ↔ in\n",
      "ignore duplicated index: European Space Agency, the\n",
      "ignore duplicated index: face off\n",
      "ignore duplicated index: face to face\n",
      "ignore duplicated index: fair dinkum\n",
      "ignore duplicated index: fall off\n",
      "ignore duplicated index: fast track\n",
      "ignore duplicated index: Fathers 4 Justice\n",
      "ignore duplicated index: Federal Reserve Bank, the\n",
      "ignore duplicated index: fiddling\n",
      "ignore duplicated index: fill in\n",
      "ignore duplicated index: first light\n",
      "ignore duplicated index: fish slice\n",
      "ignore duplicated index: follow on\n",
      "ignore duplicated index: follow something ↔ up\n",
      "ignore duplicated index: follow through\n",
      "ignore duplicated index: foul up\n",
      "ignore duplicated index: free and easy\n",
      "ignore duplicated index: Friends of the Earth\n",
      "ignore duplicated index: fully-fledged\n",
      "ignore duplicated index: get together\n",
      "ignore duplicated index: give and take\n",
      "ignore duplicated index: go ahead\n",
      "ignore duplicated index: God-given\n",
      "ignore duplicated index: good evening\n",
      "ignore duplicated index: good faith\n",
      "ignore duplicated index: go to somebody/something\n",
      "ignore duplicated index: gross somebody ↔ out\n",
      "ignore duplicated index: half and half\n",
      "ignore duplicated index: half measures\n",
      "ignore duplicated index: halves\n",
      "ignore duplicated index: hands off\n",
      "ignore duplicated index: hang up\n",
      "ignore duplicated index: hard line\n",
      "ignore duplicated index: heads up!\n",
      "ignore duplicated index: here we go\n",
      "ignore duplicated index: hold up\n",
      "ignore duplicated index: Holy Grail\n",
      "ignore duplicated index: ill-gotten gains\n",
      "ignore duplicated index: Immigration and Naturalization Service, the\n",
      "ignore duplicated index: in absentia\n",
      "ignore duplicated index: Indian Premier League\n",
      "ignore duplicated index: in house\n",
      "ignore duplicated index: in memoriam\n",
      "ignore duplicated index: Interstate Commerce Commission, the\n",
      "ignore duplicated index: Invisible Man\n",
      "ignore duplicated index: in your face\n",
      "ignore duplicated index: kick ass\n",
      "ignore duplicated index: knock somebody/something ↔ up\n",
      "ignore duplicated index: last rites\n",
      "ignore duplicated index: lay off\n",
      "ignore duplicated index: lay up\n",
      "ignore duplicated index: leading edge\n",
      "ignore duplicated index: lead off\n",
      "ignore duplicated index: leaves\n",
      "ignore duplicated index: let up\n",
      "ignore duplicated index: lie down\n",
      "ignore duplicated index: lie in\n",
      "ignore duplicated index: lift off\n",
      "ignore duplicated index: line up\n",
      "ignore duplicated index: live in\n",
      "ignore duplicated index: lives\n",
      "ignore duplicated index: lock up\n",
      "ignore duplicated index: look in\n",
      "ignore duplicated index: magic circle\n",
      "ignore duplicated index: make believe\n",
      "ignore duplicated index: make or break\n",
      "ignore duplicated index: make up\n",
      "ignore duplicated index: Man Booker Prize, the\n",
      "ignore duplicated index: mark something ↔ up\n",
      "ignore duplicated index: master\n",
      "ignore duplicated index: me too\n",
      "ignore duplicated index: microsite\n",
      "ignore duplicated index: mix somebody/something ↔ up\n",
      "ignore duplicated index: mock something ↔ up\n",
      "ignore duplicated index: Mr Right\n",
      "ignore duplicated index: natural wastage\n",
      "ignore duplicated index: new wave\n",
      "ignore duplicated index: next of kin\n",
      "ignore duplicated index: no ball\n",
      "ignore duplicated index: no-claims bonus\n",
      "ignore duplicated index: no holds barred\n",
      "ignore duplicated index: of course\n",
      "ignore duplicated index: off colour\n",
      "ignore duplicated index: off limits\n",
      "ignore duplicated index: on board\n",
      "ignore duplicated index: one another\n",
      "ignore duplicated index: on the job\n",
      "ignore duplicated index: opt out\n",
      "ignore duplicated index: Our Lady\n",
      "ignore duplicated index: Our Lord\n",
      "ignore duplicated index: out of doors\n",
      "ignore duplicated index: over the counter\n",
      "ignore duplicated index: phone in\n",
      "ignore duplicated index: pick up\n",
      "ignore duplicated index: pissed\n",
      "ignore duplicated index: player\n",
      "ignore duplicated index: play off\n",
      "ignore duplicated index: plug something ↔ in\n",
      "ignore duplicated index: pop up\n",
      "ignore duplicated index: potty mouth\n",
      "ignore duplicated index: programming\n",
      "ignore duplicated index: pull on something\n",
      "ignore duplicated index: pull out\n",
      "ignore duplicated index: pull up\n",
      "ignore duplicated index: put down\n",
      "ignore duplicated index: put out\n",
      "ignore duplicated index: put somebody/something on\n",
      "ignore duplicated index: quid pro quo\n",
      "ignore duplicated index: read something ↔ out\n",
      "ignore duplicated index: rip somebody/something ↔ off\n",
      "ignore duplicated index: roll out\n",
      "ignore duplicated index: roll up\n",
      "ignore duplicated index: round somebody/something ↔ up\n",
      "ignore duplicated index: Royal Academy, the\n",
      "ignore duplicated index: run down\n",
      "ignore duplicated index: run off\n",
      "ignore duplicated index: run somebody/something ↔ in\n",
      "ignore duplicated index: run through\n",
      "ignore duplicated index: run up something\n",
      "ignore duplicated index: see through\n",
      "ignore duplicated index: sell out\n",
      "ignore duplicated index: sell something ↔ off\n",
      "ignore duplicated index: send off\n",
      "ignore duplicated index: send something/somebody ↔ up\n",
      "ignore duplicated index: set something ↔ aside\n",
      "ignore duplicated index: set to\n",
      "ignore duplicated index: set up\n",
      "ignore duplicated index: sexual orientation\n",
      "ignore duplicated index: Shadow Cabinet\n",
      "ignore duplicated index: shelves\n",
      "ignore duplicated index: shouting match\n",
      "ignore duplicated index: show off\n",
      "ignore duplicated index: shut out\n",
      "ignore duplicated index: shut somebody in (something)\n",
      "ignore duplicated index: sit down\n",
      "ignore duplicated index: sit in\n",
      "ignore duplicated index: sit up\n",
      "ignore duplicated index: slip up\n",
      "ignore duplicated index: Slob, Wayne and Waynetta\n",
      "ignore duplicated index: softly-spoken\n",
      "ignore duplicated index: sort something/somebody ↔ out\n",
      "ignore duplicated index: spin off\n",
      "ignore duplicated index: spoilt\n",
      "ignore duplicated index: stamping ground\n",
      "ignore duplicated index: stand in\n",
      "ignore duplicated index: stand up\n",
      "ignore duplicated index: start up\n",
      "ignore duplicated index: stick up\n",
      "ignore duplicated index: stitch somebody/something ↔ up\n",
      "ignore duplicated index: Sunday driver\n",
      "ignore duplicated index: take off\n",
      "ignore duplicated index: take up\n",
      "ignore duplicated index: tear gas\n",
      "ignore duplicated index: the ACLU\n",
      "ignore duplicated index: the Acropolis\n",
      "ignore duplicated index: the Act of Union\n",
      "ignore duplicated index: the Adirondacks\n",
      "ignore duplicated index: the Admiral's Cup\n",
      "ignore duplicated index: the Adriatic Sea\n",
      "ignore duplicated index: the Aegean Sea\n",
      "ignore duplicated index: The Aeneid\n",
      "ignore duplicated index: the AFC\n",
      "ignore duplicated index: the Aga Khan\n",
      "ignore duplicated index: the Age of Enlightenment\n",
      "ignore duplicated index: the AIM\n",
      "ignore duplicated index: the Aleutian Islands\n",
      "ignore duplicated index: the Algarve\n",
      "ignore duplicated index: the Algonquin Hotel\n",
      "ignore duplicated index: the Algonquin Round Table\n",
      "ignore duplicated index: the Alhambra\n",
      "ignore duplicated index: the All Blacks\n",
      "ignore duplicated index: the Allies\n",
      "ignore duplicated index: the American Association of Retired Persons\n",
      "ignore duplicated index: the FAO\n",
      "ignore duplicated index: the Prophets\n",
      "ignore duplicated index: the States\n",
      "ignore duplicated index: throw something ↔ in\n",
      "ignore duplicated index: tie up\n",
      "ignore duplicated index: times table\n",
      "ignore duplicated index: tip somebody ↔ off\n",
      "ignore duplicated index: to and fro\n",
      "ignore duplicated index: to die for\n",
      "ignore duplicated index: top something/somebody ↔ up\n",
      "ignore duplicated index: track meet\n",
      "ignore duplicated index: trade something ↔ in\n",
      "ignore duplicated index: trade something ↔ off\n",
      "ignore duplicated index: try something ↔ out\n",
      "ignore duplicated index: tune up\n",
      "ignore duplicated index: turn off\n",
      "ignore duplicated index: turn on\n",
      "ignore duplicated index: turn up\n",
      "ignore duplicated index: under the counter\n",
      "ignore duplicated index: vise\n",
      "ignore duplicated index: Washington, D.C.\n",
      "ignore duplicated index: wash up\n",
      "ignore duplicated index: weigh in\n",
      "ignore duplicated index: welch\n",
      "ignore duplicated index: well connected\n",
      "ignore duplicated index: what if ...?\n",
      "ignore duplicated index: wind up\n",
      "ignore duplicated index: with it\n",
      "ignore duplicated index: work experience\n",
      "ignore duplicated index: work to rule\n",
      "ignore duplicated index: worse\n",
      "ignore duplicated index: worst\n",
      "ignore duplicated index: wrap up\n",
      "ignore duplicated index: write in\n",
      "ignore duplicated index: write off\n",
      "ignore duplicated index: write something ↔ up\n"
     ]
    }
   ],
   "source": [
    "# extract data from ldoce5.mdx and save to dict.json\n",
    "dict = {}\n",
    "links = {}\n",
    "for i in mdx.items():\n",
    "    entry = i[0].decode(\"utf-8\")\n",
    "    content = i[1].decode(\"utf-8\")\n",
    "    info = parse(entry, content)\n",
    "    if info:\n",
    "        index = entry\n",
    "        link = info['link']\n",
    "        definitions = info['definitions']\n",
    "\n",
    "        if definitions:\n",
    "            if index in dict:\n",
    "                print(\"ignore duplicated index: \" + index)\n",
    "            else:\n",
    "                dict[index] = {\n",
    "                    \"definitions\": definitions,\n",
    "                    \"indices\": [index] \n",
    "                }\n",
    "        else:\n",
    "            links[index] = link\n",
    "        \n",
    "for link, i in links.items():\n",
    "    if link in dict:\n",
    "        dict[link][\"indices\"].append(i)\n",
    "\n",
    "\n",
    "with open(\"./dict.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(dict, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"definitions\": [{\"business\": false, \"pron\": \"i, hi\", \"a_pron\": null, \"gram\": \"[used as the subject of a verb]\", \"level\": \"\\u25cf\\u25cf\\u25cf\", \"pos\": \"pronoun\", \"freq\": [\"S1\", \"W1\"], \"inflections\": [], \"sense\": [{\"examples\": [{\"cn_exm\": \"\\u201c\\u4fdd\\u7f57\\u5728\\u54ea\\u513f\\uff1f\\u201d\\u201c\\u4ed6\\u53bb\\u770b\\u7535\\u5f71\\u4e86\\u3002\\u201d\", \"en_exm\": \"\\u2018Where\\u2019s Paul?\\u2019 \\u2018He\\u2019s gone to the cinema.\\u2019\"}, {\"cn_exm\": \"\\u662f\\u4ed6\\u5148\\u63d0\\u51fa\\u8fd9\\u4e2a\\u60f3\\u6cd5\\u7684\\u3002\", \"en_exm\": \"It was he who first suggested the idea.\"}], \"gram_examples\": [], \"cn_sign\": null, \"en_sign\": null, \"gram\": null, \"en_def\": \"used to refer to a man, boy, or male animal that has already been mentioned or is already known about\", \"cn_def\": \"\\u4ed6\\uff1b\\u5b83\\u3014\\u6307\\u96c4\\u6027\\u52a8\\u7269\\u3015\"}, {\"examples\": [{\"cn_exm\": \"\\u6bcf\\u4e2a\\u4eba\\u90fd\\u5e94\\u6309\\u7167\\u81ea\\u5df1\\u8ba4\\u4e3a\\u6700\\u597d\\u7684\\u53bb\\u505a\\u3002\", \"en_exm\": \"Everyone should do what he considers best.\"}], \"gram_examples\": [], \"cn_sign\": null, \"en_sign\": null, \"gram\": null, \"en_def\": \"used when talking about someone who may be male or female. Some people think this use is old-fashioned.\", \"cn_def\": \"\\u4eba\\uff0c\\u4ed6\\u3014\\u6cdb\\u6307\\u7537\\u6027\\u6216\\u5973\\u6027\\uff0c\\u6709\\u4eba\\u8ba4\\u4e3a\\u8fd9\\u79cd\\u7528\\u6cd5\\u8fc7\\u65f6\\u3015\"}, {\"examples\": [], \"gram_examples\": [], \"cn_sign\": null, \"en_sign\": null, \"gram\": null, \"en_def\": null, \"cn_def\": null}]}, {\"business\": false, \"pron\": null, \"a_pron\": null, \"gram\": null, \"level\": null, \"pos\": null, \"freq\": [], \"inflections\": [], \"sense\": [{\"examples\": [], \"gram_examples\": [], \"cn_sign\": null, \"en_sign\": null, \"gram\": null, \"en_def\": \"used when writing about God\", \"cn_def\": \"\\u4e0a\\u5e1d\\u3014\\u7528\\u4e8e\\u4e66\\u9762\\u8bed\\u4e2d\\u3015\"}]}, {\"business\": false, \"pron\": \"hi\\u02d0\", \"a_pron\": null, \"gram\": \"[singular]\", \"level\": null, \"pos\": \"noun\", \"freq\": [], \"inflections\": [], \"sense\": [{\"examples\": [{\"cn_exm\": \"\\u6211\\u53d1\\u73b0\\u6885\\u5c14\\u4e0d\\u662f\\u7537\\u4eba\\uff0c\\u800c\\u662f\\u5973\\u4eba\\u3002\", \"en_exm\": \"I discovered that Mel wasn\\u2019t a he, but a she.\"}], \"gram_examples\": [], \"cn_sign\": null, \"en_sign\": null, \"gram\": null, \"en_def\": \"a male person or animal\", \"cn_def\": \"\\u7537\\u6027\\uff1b\\u96c4\\u6027\\u52a8\\u7269\"}]}, {\"business\": false, \"pron\": \"hi\\u02d0\", \"a_pron\": null, \"gram\": null, \"level\": null, \"pos\": \"prefix\", \"freq\": [], \"inflections\": [], \"sense\": [{\"examples\": [{\"cn_exm\": \"\\u516c\\u5c71\\u7f8a\", \"en_exm\": \"a he-goat\"}], \"gram_examples\": [], \"cn_sign\": null, \"en_sign\": null, \"gram\": null, \"en_def\": \"a male animal\", \"cn_def\": \"\\u3014\\u52a8\\u7269\\u3015\\u96c4\\uff08\\u6027\\u7684\\uff09\"}]}, {\"business\": false, \"pron\": null, \"a_pron\": null, \"gram\": null, \"level\": null, \"pos\": null, \"freq\": [], \"inflections\": [], \"sense\": [{\"examples\": [], \"gram_examples\": [], \"cn_sign\": null, \"en_sign\": null, \"gram\": null, \"en_def\": \"the written abbreviation of His/Her Excellency, used in the title of an  ambassador\", \"cn_def\": \"/ His/Her Excellency \\u7684\\u7f29\\u5199 \\uff0c\\u9601\\u4e0b\\u3014\\u7528\\u4e8e\\u5927\\u4f7f\\u5934\\u8854\\u3015\"}]}], \"indices\": [\"he\", \"he's\"]}\n"
     ]
    }
   ],
   "source": [
    "# generate mac dictionary xml file\n",
    "\n",
    "data = {}\n",
    "with open('./dict.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "print(json.dumps(data['he']))\n",
    "\n",
    "template_env = Environment(loader=FileSystemLoader('.'))\n",
    "template = template_env.get_template('template.html.jinja')\n",
    "rendered = template.render({\"entries\":data})\n",
    "with open(\"./LDOCE5.xml\", \"w\") as f:\n",
    "    f.write(rendered)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
